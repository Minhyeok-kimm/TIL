# 통계 이론

## 통계학이란?

- 데이터에 담겨진 표면적인 정보를 정확히 요약하고 그 내면에 담긴 의미를 추론하고 해석하기 위한 도구적인 성격의 학문

- 미지의 정보인 모수를 주어진 데이터를 이용해 맞추고자 한다. > 정확히 맞출 수 없기에 모수 예측에 오차를 가능한 한 축소시키는 것을 목표로 한다.

## 확률

### 확률의 기본 개념

- 확률: 어떤 사건이 발생할 가능성을 0에서 1사이의 숫자로 표현한 것

- 확률모형: 시행을 반복할 때마다 나오는 결과가 우연에 의존하여 매번 달라지는 현상 또는 실험(확률실험)에 대한 수리적 모형

- 표본공간: 확률 실험에서 모든 관찰 가능한 결과의 집합. S로 표기한다.<br>예: 동전을 던졌을 때 나오는 결과 S = {앞면, 뒷면}

- 사건: 표본공간의 임의의 부분집합. A, B 등으로 표기한다.

### 확률의 정의 및 성질

- 고전적 접근

    - n개의 실험결과로 구성된 표본공간에서 각 실험결과가 일어날 가능성이 같은 경우, m(m<=n)개의 실험결과로 구성된 사건 A의 확률을 아래와 같이 정의한다.
    
    $$ P(A) = \frac{M}{N} $$

- 상대적 비율에 의한 접근

    - n번의 반복된 실험 중 어떤 사건 A가 발생한 횟수를 m이라고 할 때, 사건 A의 상대빈도(상대도수)는 $frac{m}{n}$으로 구해진다.
    
    - 이 실험의 반복 횟수 n을 무한히 증가했을 때, 사건 A의 상대빈도가 수렴하는 값을 사건 A의 확률로 정의하고자 하는 접근이다.

- 확률의 공리적 정의

    1. 임의의 사건 A에 대해 P(A) >= 0
    
    2. P(S) = 1
    
    3. 표본공간 S에 정의된 서로 상호배반인 사건 $A_{1}, A_{2}, ...$에 대해 모든 사건의 합집합은 각 사건을 더한 결과와 같다.

- 공리적 접근방식: 표본공간을 정의역으로 하며, 위 세가지 공리를 만족하는 함수를 확률로 정의한다.

- 확률의 규칙

    - 여사건의 확률
    
        - $P[A^{C}]$: 사건 A를 제외한 나머지 사건의 확률
        
        - $P[A^{C}] = 1 - P[A]$
    
    - 곱사건의 확률
    
        - $P[A \cap B]$: 사건 A와 사건 B가 동시에 발생할 확률
    
    - 합사건의 확률
    
        - $P[A \cup B]$: 사건 A 또는 사건 B가 발생할 확률
        
        - $P[A \cup B] = P[A] + P[B] - P[A \cap B]$
    
- 조건부 확률과 독립

    - 조건부 확률: 사건 A와 B가 표본공간 S 상에 정의되어 있으며, P(B) > 0 라고 가정한다. 이 때 B가 일어났다는 가정 하의 사건 A가 일어날 조건부 확률은 아래 식과 같이 정의된다.
    
    $$ P(A|B) = \frac{P(A \cap B)}{P(B)} $$
    
    - 독립 사건: 두 사건 A와 B가 다음 중 하나를 만족시키면 서로 독립이라고 한다.(단, P(A) > 0, P(B) > 0)
    
        1. $P(A|B) = P(A)$
        
        2. $P(A \cap B) = P(A) * P(B)$
        
        3. $P(B|A) = P(B)$

### 베이즈 정리

#### 표본공간의 분할과 전확률 공식

- 표본공간의 분할

    - $B_{1}, ..., B_{k}$가 다음 조건을 만족하면 표본 공간 s의 분할이라고 한다.
    
        - 서로 다른 i, j에 대해 $B_{i} \cap B_{j} = \emptyset$
        
        - $B_{1} \cup B_{2} \cup ... \cup B_{k} = S$
    
    - k개의 원인이 있을 때 각각의 원인들이 만족해야 하는 조건이 분할이어야 한다.

- 전확률공식

    - 사건 $B_{1}, B_{2}, ..., B_{k}$는 상호배반이며, $B_{1} \cup ... \cup B_{k} = S$라고 함.
    
    - 이 때 S에서 정의되는 임의의 사건 A에 대하여 다음이 성립한다.
    
    $$ P(A) = P(A \cap B_{1}) + ... + P(A \cap B_{k})
            = P(B_{1})P(A|B_{1}) + ... + P(B_{k})P(A|B_{k})$$
    
    - 결과의 확률을 구할 때 어떤 원인의 확률과 그 원인을 전제로 했을 때 결과의 관계를 알면 결과의 확률을 알 수 있다.

#### 베이즈 정리

- 베이즈 정리

    - 사건 $B_{1}, B_{2}, ..., B_{k}$는 상호 배반이며, $B_{1} \cup ... \cup B_{k} = S$라고 함.<br>-> 분할이 만족해야 한다.
    
    - 이 때 사건 A가 일어났다는 조건 하에서 사건 $B_{i}$가 일어날 확률은 다음과 같다.
    
    $$ P(B_{i}|A) = \frac{P(A \cap B_{i})}{P(A)} = \frac{P(B_{i})P(A|B_{i}))}{P(B_{1})P(A|B_{1}) + ... + P(B_{k})P(A|B_{k})}$$
    
    - 베이즈 정리 활용: $B_{1}, B_{2}, ..., B_{k}$으로 분할된 사건의 각 확률을 알고, 각 $B_{i}$를 전제로 한 각 $B_{1}$의 조건부 확률을 구하기 위한 정리

### 확률과 확률분포

#### 확률변수

- 확률변수: 표본 공간에서 정의된 실수값 함수 > 사건의 결과를 실수로 바꿔준 것으로 볼 수 있다.

    - 이산형 확률변수: 확률변수가 취할 수 있는 값이 셀 수 있는 경우
    
    - 연속형 확률변수: 주어진 구간에서 모든 실수 값을 취할 수 있어 셀 수 없는 경우

- 확률분포

    - 확률질량함수(pmf): 확률변수 X가 이산형인 경우 X가 취할 수 있는 값 $x_{1}, x_{2}, ..., x_{n}$의 각각에 대하여 확률 $P[X = x{1}], P[X = x_{2}], ..., P[X = x_{n}]$을 대응시켜 주는 관계를 X의 확률질량함수라고 하며 $f(x)$로 표기한다.
    $$ f(x_{i}) = P=[X = x_{i}],   i = 1, 2, ..., n$$
    
    - 확률질량함수의 성질
    
        1. 모든 $i = 1, 2, ..., n$에 대해 $0 <= f(x_{i}) <= 1$
        
        2. $\sum_{i=1}^{n} f(x_{i}) = 1$

    - 확률밀도함수(pdf): 확률변수 X가 연속형인 경우 X가 가질 수 있는 구간 위에서의 함수 f(x)가 다음을 만족할 때, 이를 X의 확률밀도함수라고 함
    $$\int\limits_a^b f(x)dx = P[a \leq X \leq b] (단, -\infty < a < b < \infty)$$
    
    - 확률밀도함수의 성질
    
        1. 모든 a, b에 대해 $0 \leq \int\limits_a^b f(x)dx \leq 1$
        
        2. $\int\limits_\infty^\infty f(x)dx = 1$
    
    - 누적분포함수(cdf): X의 확률밀도함수가 $f(x)$일 때, X의 누적분포함수 $F(x)$는 $X \leq x$인 모든 X에 대한 $f(x)$의 적분 값이 됨. > 연속형, 이산형 모두 존재.
    
        - $F(-\infty) = 0, F(\infty) = 1$
        
        - x가 증가할 때 $F(x)$도 증가하며, $F(x)$는 음의 값을 가질 수 없음

- 확률분포의 특성치

    - 기대값: 분포의 무게중심, 중심 위치를 나타내며, $E(X) = \mu$로 표기한다.
    
        - 이산형: $\sum_{all x}^{} xf(x)$
        
        - 연속형: $\int\limits_\infty^\infty xf(x)dx$
    
    - 분산: 분포의 산포를 나타냄.
    $$V[X] = \sigma^{2} = E[(X - \mu)]$$
    
    - 표준편차: 분산의 제곱근. 단위가 보정된다.
    $$S[X] = \sigma = \sqrt{V[X]}$$

#### 확률분포

##### 1. 이항분포

- 베르누이 시행: 매 시행마다 '성공' 또는 '실패'의 오직 두 가지 가능한 결과만 가지고, '성공'의 확률이 p로 일정하다는 두 조건을 만족하는 실험

- 이항 확률변수가 고려되는 실험: 베르누이 시행을 독립적으로 n번 반복하는 실험이 해당

- 이항확률변수와 확률질량함수

    - X: n번 시행 중 '성공'의 횟수로 정의
    
    - x=0, 1, ..., n의 값을 가진다.
    
    - $f(x) = P(X = x) = A_{m,n} = \begin{pmatrix}  n \\  x \\ \end{pmatrix} p^{x}(1-p)^{n-x}$
    
    - 이 경우 $X \sim Bin[n, p]$라고 한다. > n, p를 알면 분포를 정의할 수 있음.

- 이항분포의 특성치

    - $X \sim Bin[n, p]$인 경우 $E[X] = np, V[X] = np(1-p)$를 만족한다.

##### 2. 포아송 분포

- 포아송 확률변수와 확률질량함수

    - 단위 시간에 (t=1), 포아송 확률과정을 따르는 사건 A가 발생하는 횟수를 X로 정의하면 아래와 같다.
    
    $$ f(x) = P(X = x) = \frac{exp(-m)m^{x}}{X!}, x = 0, 1, 2, ... $$
    
    - 이 경우 $X~POI[m]$라고 한다.

- 포아송 분포의 특성치

    - $X \sim POI[m]$인 경우, $E[X] = V[X] = m$을 만족한다.

##### 3. 지수분포

- 지수확률변수와 확률밀도함수

    - 단위 구간에서 평균발생횟수가 m인 포아송 확률과정을 따르는 사건 A가 한 번 일어난 뒤 그 다음 또 일어날 때까지 걸리는 시간 X로 정의됨.
    
    $$ f(x) = \frac{1}{\lambda}exp(-\frac{x}{\lambda}), x > 0임. \left(단, m = \frac{1}{\lambda}\right) $$
    
    - 이 경우  $X \sim EXP[\lambda]$ 라고 한다.

- 지수 분포의 특성치

    - 포아송 모수와 지수 모수는 역의 관계: 단위구간 내 평균 발생횟수가 m인 포아송 과정을 따르는 사건은 사건 사이 소요시간의 평균이 $\lambda = \frac{1}{m}$이다.
    
    - $X \sim EXP[\lambda]$인 경우, $E[X] = \lambda$를 만족한다.

##### 4. 감마분포

- 감마확률변수와 확률밀도함수

    - 감마확률변수 X의 확률밀도함수는 양수인 $\theta$와 k에 대하여 다음과 같이 정의된다.
    
    $$ f(x) = \frac{1}{\theta^k\gamma(k)}x^{k-1}exp(-x/\theta), x > 0 $$
    
    - 이 경우 $X \sim GAMMA[k, \theta]$라고 한다. > k는 shape를 결정하는 모수, $\theta$는 스케일(분포)를 결정하는 모수.

- 감마분포의 특성치

    - $X \sim GAMMA[k, \theta]$인 경우에 $E[X] = k\theta, V[X] = k\theta^{2}$

##### 5. 정규분포

- 정의

    - 확률변수 X가 평균이 $\mu$, 분산이 $\sigma^{2}$이고, 다음의 확률밀도함수를 가질 때, X는 정규분포를 따른다고 하며, 이 경우 $X \sim N[\mu, \sigma^{2}]$라고 한다.

    $$ f(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^{2}}{2\sigma^{2}}}, -\infty < x < \infty $$

- 정규분포 확률밀도함수의 개형

    - $\mu$는 분포의 중심.
    
    - $\mu$를 중심으로 대칭이고, $\mu$에서 가장 큰 값이 되는 하나의 봉우리만 가진다.
    
    - $\sigma^{2}$이 크면 분포의 산포가 커지고, 작으면 분포의 산포가 작아진다.

- 정규분포의 특성치

    - $X \sim N[\mu, \sigma^{2}]$인 경우, $E[X] = \mu, V[X] = \sigma^{2}$

##### 6. 표준정규분포

- 표준정규분포와 정규확률변수의 표준화

    - 표준정규분포
    
        - $X \sim N[\mu, \sigma^{2}]$일 때, 정규분포의 선형불변성에 의해 $Z = \frac{X-\mu}{\sigma} \sim N[0, 1]$이 되며, 이 때 평균이 0, 분산이 1인 정규분포를 표준정규분포라 정의한다.
        
        $$ f(z) = \frac{1}{\sqrt{2\pi}}e^{-x^{2}/2}, -\infty < z < \infty $$

    - 표준화: 정규확률분포를 $Z = \frac{X-\mu}{\sigma}$을 이용하여 표준정규분포로 변경할 수 있다. 이 과정을 표준화라고 한다.

    - 표준정규 확률변수의 (1-$\alpha$)분위수: $z_{\alpha}$
    
        - $Z \sim N[0, 1]$일 때, $P[Z < c] - 1 - \alpha$를 만족하는 Z의 $(1 - \alpha)$분위수 c를 $Z_{\alpha}$으로 표기한다.
        
        - $Z_{0.05} = 1.645, Z_{0.025} = 1.96$

##### 7. 카이제곱 분포

- 정의

    - $Z_{1}, Z_{2}, ..., Z_{k}가 k개의 서로 독립인 표준정규 확률변수 ($Z_{i} \sim N[0, 1], i = 1, 2, ..., k$)라고 할 때, $X = Z_{1}^{2}+Z_{2}^{2}+...+Z_{k}^{2}$가 따르는 분포를 자유도가 k인 카이제곱 분포라고 정의함. > 표준정규들의 제곱합이 가지는 분포
    
    $$ f(x) = \frac{1}{r\left(\frac{1}{2}\right)2^{\frac{k}{2}}}x^{\frac{k}{2}-1}e^{-\frac{x}{2}}, 0 < x < \infty$$
    
    - 이 경우 $X \sim x^{2}[k]$라고 함.

- 카이제곱 분포의 특성치

    - $X \sim x^{2}[k]$인 경우, $E[X] = k, V[X] = 2k$를 만족한다.

- 카이제곱 분포 확률밀도함수 개형: 오른쪽 꼬리가 길게 늘어진 비대칭 형태이다.

- 카이제곱 확률변수의 $(1 - \alpha)$분위수 : $X^{2}_{a, k}$

    - $X \sim x^{2}[k]$일 때, $P[X > c] = \alpha$를 만족하는 $X$의 $(1 - \alpha)$분위수 c를 $X^{2}_{a, k}$으로 표기한다.

##### 8. t 분포

- 정의

    - Z가 표준정규 확률변수 $Z \sim N[0, 1]$이라 할 때, U가 자유도가 k인 카이제곱 확률변수 $U \sim x^2[k]$이며, Z와 X는 서로 독립이라고 할 때, $X = \frac{z}{\sqrt{U/k}}$가 따르는 분포를 자유도가 k인 t분포라고 정의한다. > 표준정규의 평균이 가지는 분포
    
    $$ f(x) = \frac{r\left(\frac{k + 1}{2}{2}\right)}{r\left(\frac{k}{2}\right)}\frac{1}{\sqrt{kl\pi}}\frac{1}{\left(1 + \frac{x^2}{k}]\right)^{\frac{k + 1}{2}}}, -\infty < x < \infty$$
    
    - 이 경우 $X \sim t[k]$라고 한다.

- t 분포의 특성치

    - $X \sim t[k]$인 경우, $E[X] = 0, V[X] = \frac{k}{k-2}$(단, k > 2)를 만족한다.

- t분포 확률밀도함수 개형

    - $X \sim t[k]$인 경우
    
    1. 가운데 0을 중심으로 대칭인 종모양의 분포
    
    2. 표준정규분포보다 꼬리가 두껍다
    
    3. 자유도 k가 커짐에 따라 산포가 줄어들어 표준정규분포로 수렴한다.

- t 확률변수의 $(1 - \alpha)$분위수: $t_{a, k}$

    - $X \sim t[k]$일 때, $P[X > c] = \alpha$를 만족하는 X의 $(1 - \alpha)$분위수 c를 $t_{a, k}$으로 표기한다.

##### 9. F 분포

- 정의

    - U가 자유도가 $k_1$인 카이제곱 확률변수 $U \sim x^2[k_1]$이며, V가 자유도가 $k_2$인 카이제곱 확률변수 $V \sim x^2[k_2]$이고, U와 V는 서로 독립이라고 할 때, $X = \frac{U/k_1}{V/k_2}$가 따르는 분포를 자유도가 $k_1, k_2$인 F분포라고 정의한다. > 2개의 카이제곱분포의 비율이 만들어내는 분포
    
    $$ f(x) = \frac{r\left(\frac{k_1+k_2}{2}\right)}{r\left(\frac{k_1}{2}\right)r\left(\frac{k_2}{2}\right)}\left(\frac{k_1}{k_2}\right)^{\frac{k_1}{2}}x^{\frac{k_1}{2}-1}\left(1 + \frac{k_1}{k_2}x\right)^{-\frac{1}{2}(k_1 + k_2)}, 0 < x < \infty$$
    
    - 이 경우 $X \sim F[k_1, k_2]$라고 한다.

- F분포의 특성치

    - $X \sim F[k_1, k_2]인 경우, $E[X] = \frac{k_2}{k_2-2}, V[X] = \frac{2k\frac{2}{2}(k_1+k_2-2)}{k_1(k_2-2)^2(k_2-4)}$를 만족한다.

- F분포 확률밀도함수 개형

    - 카이제곱 분포처럼 오른쪽으로 치우친 비대칭 구조이다.

- F확률변수의 $(1 - \alpha)$분위수: $F_{\alpha, k_1, k_2}$

    - $X \sim F[k_1, k_2]$일 때, $P[X > c] = \alpha$를 만족하는 X의 $(1 - \alpha)$분위수 c를 $F_{\alpha, k_1, k_2}$으로 표기한다.

# 탐색적 데이터 분석

## 그래프에 의한 기술통계

### 데이터 시각화 개요

- 그래프를 이용한 자료의 정리: 자료의 유형에 맞는 그래프를 이용하여 한눈에 알아볼 수 있게 자료를 시각화할 수 있음

- 질적 자료인 경우 변수 1개일 때 바차트, 파이차트를 확인할 수 있고, 변수 2개인 경우 히트맵, 스택드컬럼차트를 확인할 수 있다.

- 양적 자료인 경우 변수 1개일 때 히스토그램, 박스플롯, 라인차트, QQ플롯을 확인할 수 있고, 변수 2개일 때 산점도를 확인할 수 있다.

## 수치적 기술통계

### 위치, 변이, 모양통계량

#### 1. 중심 위치 척도

- 평균

    - 표본 자료 $x_1, ..., x_n$이 주어졌을 때, 전체 데이터의 합을 개수로 나눈 것을 표본평균이라고 한다.
    
    - 이상치에 민감하다는 단점이 있다.

- 중위수, 중앙값(Median)

    - 표본 자료 $x_1, ..., x_n$을 오름찻훈으로 정렬하였을 때, 중간에 위치한 값.
    
    - n이 홀수인 경우 $\frac{n+1}{2}$번째 자료, n이 짝수인 경우 $\frac{n}{2}$번째와 $\frac{n}{2}+1$번째 자료의 평균이다.
    
    - 평균과 다르게 이상치에 민감하지 않다.

- 최빈값(Mode)

    - 가장 빈도가 높은 값 또는 구간을 말한다.

- 분포의 치우침 유형별 척도들 간의 관계

    - 오른쪽 꼬리가 긴 경우(왼쪽으로 치우친 경우): 최빈값 < 중앙값 < 평균 순서
    
    - 가운데를 중심으로 대칭형(종 모양): 최빈값 = 중앙값 = 평균
    
    - 왼쪽 꼬리가 긴 경우(오른쪽으로 치우친 경우): 평균 < 중앙값 < 최빈값 순서

#### 2. 상대적 위치 척도

- 사분위수(Quartile): Q1, Q2, Q3

    - Q1: 25%에 해당하는 수. 1사분위수
    
    - Q2: 중앙값. 2사분위수
    
    - Q3: 75%에 해당하는 수. 3사분위수

#### 3. 변동성 척도

- 범위(Range)

    - 표본 자료 $x_1, ..., x_n$이 주어졌을 때, $max(x_i) = min(x_i)$를 범위라고 한다.

- 사분위간 범위(IQR, Inter Quartile Range)

    - Q3 - Q1

- 표본 분산(Sample Variance)

    - 표본 자료 $x_1, ..., x_n$이 주어졌을 때, 
    
    $$ s^2 = \frac{\sum_{i=1}^{n} (x_i - \overline{x})^2}{n - 1} $$

- 표본 표준편차(Sample Standard Deviation)

    - $ s = \sqrt{s^2}$

- 변동계수(Coefficient of Variation)

    - $ cv = s/\overline{x} $
    
    - 자료의 단위가 다르거나 스케일의 차이가 큰 경우 활용한다.

#### 4. 형태 척도

- 분포의 형태에 관한 척도

    - 왜도: 분포의 비대청 정도를 나타내는 척도. 음의 값인 경우 오른쪽으로 치우쳐진 분포이고, 양의 값인 경우 왼쪽으로 치우쳐진 분포이다.
    
    - 첨도: 분포의 중심에서 뽀족함 정도를 나타내는 척도. 정규분포인 경우는 첨도가 0이며, 양수가 나오는 경우 정규분포보다 더 뽀족한 형태이고, 음수인 경우는 정규분포보다 더 평평한 형태이다.

### 연관성

#### 1. 선형적 연관성

- 두 숫자형 변수의 선형적 연관성

    - 선형적 연관성의 방향: 양의 선형관계의 경우 오른쪽 위로 향하는 형태, 음의 선형관계의 경우 오른쪽 아래로 향하는 형태이다.
    
    - 선형적 연관성의 강도: 모여있는 정도에 따라 약한지, 강한지 파악

#### 2. 선형적 연관성 척도

- 표본 공분산(Sample Covariance)

    - n쌍의 표본 자료가 주어졌을 때, 
    
    %% s_{xy} = \frac{\sum_{i=1}^{n}(x_i - \overline{x}(y_i - \overline{y}))}{n-1} $$
    
    - 선형관계의 방향
    
        - $s_{xy} > 0$: 양의 선형 관계, 비례 관계
        
        - $s_{xy} < 0$: 음의 선형 관계, 반비례 관계
    
    - 선형관계의 강도
    
        $ -S_xS_y <= S_{xy} <= s_xs_y $
    
    - 표본 공분산은 x와 y의 측정 단위에 의존하는 지표이다.<br>
    $ x^{a} = ax + b$이고, $y^{a} = cy + d$인 경우, $s_{x^{a}y^{a}} = ac * S_{xy}$이다.

- 표본 상관계수(Sample Correlation, 피어슨 상관계수)

    - $r_{xy} = \frac{S_{xy}}{S_xS_y}$
    
    - $ -1 <= r_{xy} <= 1 $
    
    - 선형관계의 방향
    
        - $r_{xy} > 0$: 양의 선형관계
        
        - $r_{xy} < 0$: 음의 선형관계
    
    - 선형관계의 강도:
    
        - $|r_{xy}| \approx 0$: 강도가 약함
        
        - $|r_{xy}| \approx 1$: 강도가 강함
    
    - 표본 상관계수는 x와 y의 측정 단위에 의존하지 않음.
    
        - $ x^{a} = ax + b, y^{a} = cy + d $이고, ac > 0인 경우, $ r_{x^{a}y^{a}} = r_{xy} $

- 순위를 이용한 상관계수

    - 서열 척도이거나 정규분포를 심하게 벗어나는 두 숫자형 변수의 연관성을 파악할 때 사용
    
    - 스피어만 상관계수(Spearman's correlation coefficient)
    
        - 원 자료값의 순위를 구한 뒤, 순위에 대해 피어슨의 상관계수를 구한 것
        
        - -1에서 1사이의 값을 가지며, 절대값이 클수록 강한 상관관계를 나타낸다.
    
    - 켄달 상관계수(Kendall rank correlation ceofficeient, 켄달의 타우)
    
        - 두 변수 순위의 일치 정도를 측정
        
        - 한 변수의 순위가 증가할 때 다른 변수의 순위도 함께 증가하는 경우가 그렇지 않은 경우에 비해 얼마나 큰지를 측정하는 방식
        
# 추정과 검정

## 통계적 추론

### 통계적 추론 개요

- 모수와 통계량 각각의 기호

    - 평균: $\mu$(모평균), $\overline{X}$(표본평균)
    
    - 분산: $\sigma = V[X]$(모분산), $S^2$(표본분산)
    
    - 표준편차: $\sigma$(모표준편차), $S$(표본표준편차)

- 모집단의 분포와 확률표본

    - 모집단의 변수 X의 확률분포함수를 f(x)로 가정.
    
    - 모집단 f(x)로부터의 확률표본(iid 표본) $X_1, X_2, ..., X_n$은 다음의 두가지 성질을 만족하는 모집단 f(x)로부터의 표본을 뜻한다.
    
        - 각 표본은 서로 독립이다.
        
        - 표본은 모두 동일하게 f(x)의 분포를 따른다.

- 통계량과 표본분포

    - 통계량: 확률표본 $X_1, X_2, ..., X_n$의 함수에서 평균, 분산, 표준편차 등
    
    - 표본분포: 통계량의 확률분포

### 표본추출법

- 표본추출 방법

    - 모집단을 대표할 수 있도록 표본을 추출하는 것이 가장 중요하다.
    
    - 표본추출방법에 따라 분석 결과 및 해석에 큰 차이가 발생할 수 있다.
    
    - 대표적인 4가지 표본 추출방법: 단순임의 추출법(simple random sampling), 계통추출법(systematic sampling), 집락추출법(cluster sampling), 층화추출법(stratified sampling)

- 단순임의 추출법

    - 모집단을 구성하는 모든 원소에 대해 표본으로 추출될 확률을 동일하게 해주는 표본 추출법
    
    - 난수표에서 난수를 발생시켜 표본을 추출
    
        - N개의 원소로 구성된 모집단에서 $n(<=N)$개의 표본을 추출할 때 각 원소에 1, 2, ..., N까지의 번호를 부여하고 여기서 n개의 번호를 임의로 선택해 그 번호에 해당하는 원소로 표본을 추출하는 방법

- 계통 추출법

    - N개의 원소로 구성된 모집단에서 n개의 표본을 추출할 때, 각 원소에 1, 2, ..., N까지의 번호를 부여하고 이를 순서대로 나열한다.
    
    - K개씩 n개의 구간으로 나눈 뒤 첫번째 구간에서 K개의 원소 중 하나를 임의로 선택하고, 그 이후 K개씩 띄어서 표본을 추출

- 집락 추출법

    - 모집단이 몇 개의 집락(cluster)이 결합된 형태로 구성되어 있고, 각 집락에서 원소들에게 일련번호를 부여할 수 있는 경우에 이용
    
    - 일부 집락을 랜덤하게 선택한 뒤, 선택된 각 집락에서 표본을 임의로 선택한다.

- 층화 추출법

    - 상당히 이질적인 원소들로 구성된 모집단에서 각 계층을 고루 대표할 수 있도록 표본을 추출. 이질적인 모집단의 원소들을 서로 유사한 것끼리 몇 개의 층(stratum)으로 나눈 후, 각 층에서 표본을 랜덤하게 추출한다.

## 추정

### 통계적 추론 - 추정 개요

- 추정: 모수를 맞추는 것

- 추정량: 모수 $\theta$의 추정에 사용되는 통계량을 $\theta$의 추정량($\widehat{\theta}$으로 표기)이라고 한다. 관찰된 표본자료로 추정량의 값을 계산한 것을 추정치라고 한다.

- 점추정과 구간추정

    - 점추정(point estimation): 하나의 모수를 한 개의 값으로 추정
    
    - 구간 추정(interval estimation): 모수가 포함되리라 기대되는 구간으로 모수를 추정

- 신뢰구간

    - 모수 $\theta$에 대한 신뢰구간 도출을 위해서 알아야 하는 것은 추정량 $\widehat{\theta}$, 추정량 $\widehat{\theta}$의 표본분포(일반적으로 모수 $\theta$에 의존)가 있다.
    
    - 신뢰구간의 정의: $\theta$의 추정량 $\widehat{\theta}$을 적절하게 변형한 L과 U이 있어 다음을 만족하는 경우, $$ P[L <= \theta <= U] = 1 - \alpha, 0 <= \alpha <- 1$$ 구간 (L, U)을 $\theta$의 100(1-$\alpha$)% 신뢰구간이라고 한다. 여기서 100(1-$\alpha$)%를 신뢰수준이라고 한다.
    
    - 신뢰구간의 해석
    
        - 신뢰수준은 동일한 구간 추정법을 반복적으로 사용할 때 얻어지는 신뢰구간들이 참값 $\theta$를 품을 확률을 의미한다.
        
        - $\mu$에 관한 추정에서 신뢰수준 90%의 의미는 n개의 표본을 추출하는 과정을 반복하여 매번 이 구간 추정식으로 신뢰구간을 계산한다면, 이들 중 90%에 해당하는 신뢰구간들이 참값 $\mu$를 포함하는 것을 의미
        
        - n개의 표본으로 구한 하나의 신뢰구간에 모수가 포함되었는지의 여부는 알 수 없다.

## 가설검정

### 기본 개념

- 통계적 가설검정이란 표본으로부터 주어지는 정보를 이용하여 모수에 대한 예상, 주장 또는 추측 등의 옳고 그름을 판정하는 과정이다.

- 가설

    - 통계적 가설은 모수에 대한 예상, 주장 또는 추측을 표현한 것이다.
    
    - 귀무가설($H_0$): 지금까지 사실로 알려져 있는 가설
    
    - 대립가설($H_1$): 표본자료로부터의 강력한 증거에 의해 입증하고자 하는 가설
    
    - 가설검정은 표본의 정보가 귀무가설 $H_0$에 대한 충분한 반증이 되는가를 보는 것
    
    - 결론도 "귀무가설 $H_0$을 기각" 또는 "귀무가설 $H_0$을 기각하지 못함" 중 하나로 표현한다.

- 가설 유형: 관심 모수가 $\mu$이고, 검정하고자 하는 모수의 경계값이 $\mu_0$라고 할 때, 단측 검정과 양측 검정이 있다.

    - 단측 검정
    
        - 왼 꼬리 검정: $H_0: \mu = \mu_0, H_1: \mu < \mu_0$
        
        - 오른 꼬리 검정: $H_0: \mu = mu_0, H_1: \mu > \mu_0$
    
    - 양측 검정: $H_0: \mu = \mu_0, H_1: \mu \neq \mu_0$

- 검정통계량

    - 귀무가설 $H_0$과 대립가설 $H_1$ 중 어느 하나를 택하는 기준을 결정하는 통계량
    
    - 모집단이 모분산이 알려진 정규분포인 경우, 모평균 $\mu$에 관한 검정의 경우,
    
        - 검정통계량: 표본평균 $\overline{X}$의 함수인 $ Z = \frac{\overline{X} - \mu}{\sigma/\sqrt{n}}$
        
        - 검정통계량 표본분포: $Z = \frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \sim N[0, 1]$
        
        - 귀무가설 $H_0: \mu = \mu_0$이 사실일 때, $ Z = \frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \sim N[0, 1]$

- 귀무가설 $H_0$의 기각여부를 판단하기 위한 두 가지 접근 방식

    - 기각역(귀무가설 $H_0$을 기각하게 하는 검정통계량 관측치의 영역)에 의한 검정
    
    - 유의확률에 의한 검정
    
    - 두 방식은 동일한 결론을 가진다.

- 유의확률에 의한 검정 방법

    - 유의확률(p-value): 귀무가설 $H_0$가 사실인 경우의 검정통계량 분포에서, 대립가설 $H_1$의 방향으로, 검정통계량의 관찰값보다 더 극단적인 값이 나올 확률로 계산
    
    - 모분산 $\sigma^2$이 알려진 정규 모집단에서 모평균 $\mu$에 관한 검정의 경우 귀무가설 $H_0$이 사실일 때, 검정통계량 Z의 분포에서 $z_0$(= 표본자료로부터 계산된 검정통계량의 값)을 이용하여 계산
    
    - 유의확률의 해석: 유의확률은 값이 작을수록 해당하는 표본은 귀무가설 $H_0$가 사실인 경우의 표본으로 보기 어려우며, 대립가설 $H_1$을 더욱 지지하는 것으로 해석할 수 있다. 즉, 유의확률이 일정수준보다 작으면 귀무가설 $H_0$를 기각한다.

- 가설검정에서의 의사결정에서 발생할 수 있는 오류

    - 제 1종 오류: 실제로는 귀무가설 $H_0$가 사실인데, 귀무가설 $H_0$을 기각하게 되는 오류이며, 제 1종 오류의 확률을 $\alpha$로 표기한다.
    
    - 제 2종 오류: 실제로는 대립가설 $H_1$이 사실인데, 귀무가설 $H_0$을 기각하지 못하게 되는 오류이며, 제 2종 오류의 확률을 $\beta$로 표기한다.

- 유의수준 100 $\alpha$ %의 검정법

    - 검정의 오류: 두 종류의 오류는 서로 상충관계로 동시에 줄이기 어렵다. 그렇기에 더 위험한 제1종 오류가 일정 수준을 넘지 못하도록 제한하면서 제2종 오류를 최소로 하는 검정법을 찾고자 한다.
    
    - 유의수준: 제1종 오류를 범할 확률의 최대 허용 한계
    
    - 자료로부터 계산된 유의확률(p-value)이 주어진 유의수준 $\alpha$보다 작은 경우에 귀무가설 $H_0$를 기각한다. 즉, 유의확률(p-value) <= 유의수준($\alpha$)면, 귀무가설 $H_0$를 기각